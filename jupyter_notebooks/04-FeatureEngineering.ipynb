{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Feature Engineering Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Engineer features for Regression model\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/cleaned/TrainSetCleaned.csv\n",
    "* outputs/datasets/cleaned/TestSetCleaned.csv \n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate a list with variables to engineer \n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* Feature Engineering Transformers\n",
    "  * Ordinal categorical encoding\n",
    "  * Numerical Variable Transformation - Numerical transformer\n",
    "  * Outlier Transformer - Winzorizer\n",
    "  * Smart Correlation Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MWW8E7lz3i7"
   },
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
    "TrainSet = pd.read_csv(train_set_path)\n",
    "TrainSet.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = 'outputs/datasets/cleaned/TestSetCleaned.csv'\n",
    "TestSet = pd.read_csv(test_set_path)\n",
    "TestSet.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate which potential transformation could be used on the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigation from the Panda Profiling shows:\n",
    "\n",
    "* We have 4 categorical - BsmtExposure, BsmtFinType1, GarageFinish, KitchenQual. The approach here uses **Ordinal Encoder** from the Categorical Variable Encoding transformer to transform each class to numbers.\n",
    "\n",
    "* The remaining 20 numerical variables will use **Numerical Variable Transformation** to transform the variable distribution, ideally to become close to a normal distribution.\n",
    "\n",
    "* Most of the variables have distribution with some outliers. We will assess engineered variables distribution using **Winzorizer** to cap outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform another Correlation and PPS analysis on the cleaned datasets.\n",
    "\n",
    "A custom functions where a combined correlation analysis (Pearson and Spearman) and PPS is used Hence, there will be need to call two functions:\n",
    "\n",
    "CalculateCorrAndPPS(): calculate correlation tables and PPS table for a dataset. Then prints Q1 and Q3 for PPS scores\n",
    "DisplayCorrAndPPS(): which takes the following arguments; df_corr_pearson, df_corr_spearman, pps_matrix and the visualization threshold for correlations and PPS (CorrThreshold and PPS_Threshold) respectively.\n",
    "We build heatmaps for PPS and Pearson and Spearman correlation\n",
    "\n",
    "Note: The custom functions was taken from the Code Institute lesson on Exploratory Data Analysis Tools on \"Predictive Power Score Unit 1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\")\n",
    "    df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "    print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call CalculateCorrAndPPS to calculate the Correlation levels and PPS Scores matrix on the Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(TrainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PPS threshold shows there is strong predictive power in range of 0 and 0.05. The correlation threshold will be set to 0.6 (strong correlation) and a PPS threshold of 0.15, which I think is a moderate correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
    "                  df_corr_spearman=df_corr_spearman, \n",
    "                  pps_matrix=pps_matrix,\n",
    "                  CorrThreshold=0.6, PPS_Threshold=0.15,\n",
    "                  figsize=(10,10), font_annot=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some changes occured in the Correlation level and the PPS analysis when compare the data cleaning notebook using the same threshold:\n",
    "\n",
    "* Raw Data Analysis - Spearman correlation: suggests that Sales Price has moderate Correlation with GarageArea, TotalBsmtSF and YearBuilt, while Sales Price have strong monotonic relationships with GrLivArea and OverallQual.\n",
    "\n",
    "* Cleaned Data Analysis: While most of these variables have no major changes, except TotalBsmtSF now have 1 has the correlation with sales price in the cleaned data. \n",
    "\n",
    "* Raw Data Analysis - Pearson correlation: Plot shows that OverallQual, GrLivArea, GarageArea, 1stFlrSF and TotalBsmtSF have strong to moderate linear relationships with Sales Price.\n",
    "\n",
    "* Cleaned Data Analysis: While most of these variables have no major changes, except TotalBsmtSF have made slight improvement to the correlation with sales price in the cleaned data. However, still moderate correlation.\n",
    "\n",
    "  * 1stFlrSF still show high correlation level with TotalBsmtSF\n",
    "  * GarageYrBlt still show high correlation level with YearBuilt\n",
    "  * YearRemodAd shows high correlation level with YearBuilt, KitchenQual and GarageYrBlt\n",
    "  * Correlation level amongst variables have drop slightly in the clean data\n",
    "\n",
    "* Raw Data Analysis - PPS Heatmap: A PPs greater than 0.2 usually means a strong predictive power. The Plot shows that KitchenQual OverallQual and YearBuilt have strong predictive power with Sales Price, while GarageArea and GarageFinish having some predictive power but weak.\n",
    "\n",
    "* Cleaned Data Analysis - PPS Heatmap: KitchenQual OverallQual and YearBuilt remains the same while, GarageArea has now gain some stronger predictive power. \n",
    "  * GarageFinish has lost its weak predictive power. GarageYrBlt now having some predictive power but weak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the custom function in the Code Institute feature-engine lesson material and Churnometer walkthrough project in the  feature engineering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
    "    \"\"\"\n",
    "    - used for quick feature engineering on numerical and categorical variables\n",
    "    to decide which transformation can better transform the distribution shape\n",
    "    - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
    "    \"\"\"\n",
    "    check_missing_values(df)\n",
    "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
    "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "\n",
    "    # Loop in each variable and engineer the data according to the analysis type\n",
    "    df_feat_eng = pd.DataFrame([])\n",
    "    for column in df.columns:\n",
    "        # create additional columns (column_method) to apply the methods\n",
    "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "        for method in list_column_transformers:\n",
    "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "\n",
    "        # Apply transformers in respective column_transformers\n",
    "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
    "            analysis_type, df_feat_eng, column)\n",
    "\n",
    "        # For each variable, assess how the transformations perform\n",
    "        transformer_evaluation(\n",
    "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "\n",
    "    return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "    \"\"\" Check analysis type \"\"\"\n",
    "    if analysis_type is None:\n",
    "        raise SystemExit(\n",
    "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "    if analysis_type not in allowed_types:\n",
    "        raise SystemExit(\n",
    "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        raise SystemExit(\n",
    "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
    "    if analysis_type == 'numerical':\n",
    "        list_column_transformers = [\n",
    "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        list_column_transformers = ['iqr']\n",
    "\n",
    "    return list_column_transformers\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "    if analysis_type == 'numerical':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    return df_feat_eng, list_applied_transformers\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "    # For each variable, assess how the transformations perform\n",
    "    print(f\"* Variable Analyzed: {column}\")\n",
    "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "    for col in [column] + list_applied_transformers:\n",
    "\n",
    "        if analysis_type != 'ordinal_encoder':\n",
    "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        else:\n",
    "            if col == column:\n",
    "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "            else:\n",
    "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
    "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "    sns.boxplot(x=df[variable], ax=axes[2])\n",
    "\n",
    "    axes[0].set_title('Histogram')\n",
    "    axes[1].set_title('QQ Plot')\n",
    "    axes[2].set_title('Boxplot')\n",
    "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
    "                                 f\"{column}_ordinal_encoder\"])\n",
    "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # Winsorizer iqr\n",
    "    try:\n",
    "        disc = Winsorizer(\n",
    "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
    "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_iqr\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # LogTransformer base e\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_e\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
    "\n",
    "    # LogTransformer base 10\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_10\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
    "\n",
    "    # ReciprocalTransformer\n",
    "    try:\n",
    "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
    "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
    "\n",
    "    # PowerTransformer\n",
    "    try:\n",
    "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
    "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_power\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
    "\n",
    "    # BoxCoxTransformer\n",
    "    try:\n",
    "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
    "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_box_cox\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
    "\n",
    "    # YeoJohnsonTransformer\n",
    "    try:\n",
    "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
    "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
    "    \n",
    "    return df_feat_eng, list_methods_worked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the summary of the potential feature engineering transformers considered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical Variable Encoding - Ordinal Encoder\n",
    "* Numerical Variable Transformation - Numerical transformer\n",
    "* Outlier - Winzorizer\n",
    "* Smart Correlation Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding - Ordinal: replaces categories with ordinal numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering= ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create a DataFrame, with the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the engineered variables and apply the transformations, assess the engineered variables distribution and select the most suitable method for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='ordinal_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation is effective, it converted all the categorical classes to numbers. Although, the distribution still remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the selected transformation to the Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(encoding_method='arbitrary', variables = variables_engineering)\n",
    "TrainSet = encoder.fit_transform(TrainSet)\n",
    "TestSet = encoder.transform(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the transformation for TrainSet and TestSet application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet.filter(variables_engineering).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet.filter(variables_engineering).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Numerical variables except the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering = (TrainSet.select_dtypes(include=['float', 'int']).columns.to_list())\n",
    "variables_engineering.remove('SalePrice')\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame, with the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the engineered variables and apply the transformations, assess the engineered variables distribution and select the most suitable method for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable transformation distribution analysis - Assessed variables distribution to select the most suitable method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables :\n",
    "\n",
    "1. **1stFlrSF:** For 1stFlrSF, it was possible to apply  all the numerical Transformer. They all show similar results in normalizing the data.\n",
    "\n",
    "**Conclusion** - log_e have been selected for this transformation.\n",
    "\n",
    "2. **2ndFlrSF:** Only power and Yeo-Johnson were applied to this variables, both did not normalize the data. As the variable majorly contains zeros\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "3. BedroomAbvGr: No improvement seen in distribution from any of the transformed variable.\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "4. BsmtExposure: No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "5. BsmtFinSF1: Only power and Yeo-Johnson were applied to this variables, slight improvement in data distribution. Although only presence of lower boundry and no outliers in the Boxplot, indicating lost of some extreme value.\n",
    "\n",
    "**Conclusion** - Power have been selected for this transformation.\n",
    "\n",
    "6. **BsmtFinType1**: No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "7. **BsmtUnfSF**: Both power and Yeo-Johnson made slight improvement with the data distribution. Though there was no presence of outliers, both transformers didn't help the distribution, but help with the abnormalty.\n",
    "\n",
    "**Conclusion**- Power have been selected for this transformation.\n",
    "\n",
    "8. **EnclosedPorch:**  Only power and Yeo-Johnson were applied to this variables. No improvement seen in distribution from the transformation.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "9. **GarageArea:** Only Power and Yeo-Johnson were applied to this variables. Both power and Yeo-Johnson made slight improvement with the data distribution.\n",
    "\n",
    "**Conclusion** - power have been selected for this transformation.\n",
    "\n",
    "10. **GarageFinish:**  EnclosedPorch:  Only power and Yeo-Johnson were applied to this variables. No improvement seen in distribution from the transformation.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "11. **GarageYrBlt:** It was possible to apply all the numerical Transformer. They made slight improvement to the data distribution seen in 'yeo_johnson' and 'box_cox'.\n",
    "\n",
    "**Conclusion** - yeo_johnson have been selected for this transformation.\n",
    "\n",
    "12. **GrLivArea:** It was possible to apply all the numerical Transformer. Some improvement seen in the distribution and the QQ Plot diagonal line of the transformer except for reciprocal transformer.\n",
    "\n",
    "**Conclusion** - log_e have been selected for this transformation.\n",
    "\n",
    "13. **KitchenQual:** Only power and Yeo-Johnson were applied to this variables. No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "14. **LotArea:** It was possible to apply all the numerical Transformer. Some improvement seen in the distribution and the QQ Plot diagonal line of the transformer except for reciprocal transformer.\n",
    "\n",
    "**Conclusion** - log_e have been selected for this transformation.\n",
    "\n",
    "15. **LotFrontage:** It was possible to apply all the numerical Transformer. Some improvement seen in the distribution. They all show similar results in normalizing the data.\n",
    "\n",
    "**Conclusion** - yeo_johnson have been selected for this transformation.\n",
    "\n",
    "16. **MasVnrArea:** Only power and Yeo-Johnson were applied to this variables. No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "17. **OpenPorchSF:** Only power and Yeo-Johnson were applied to this variables. Slight improvement in data distribution from both transformation. Although only presence of lower boundry and no outliers in the Boxplot, indicating lost of some extreme value.\n",
    "\n",
    "**Conclusion** - yeo_johnson have been selected for this transformation.\n",
    "\n",
    "18. **OverallCond:** It was possible to apply all the numerical Transformer. No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "19. **OverallQual:** It was possible to apply all the numerical Transformer. No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "20. **TotalBsmtSF:** Only power and Yeo-Johnson were applied to this variables. Some improvement seen in the distribution. They all show similar results in normalizing the data.\n",
    "\n",
    "**Conclusion** - yeo_johnson have been selected for this transformation.\n",
    "\n",
    "21. **WoodDeckSF:** Only power and Yeo-Johnson were applied to this variables. No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected\n",
    "\n",
    "22. **YearBuilt:** It was possible to apply all the numerical Transformer. Both box_cox and Yeo-Johnson made slight improvement with the data distribution. Though there was no presence of outliers, both transformers didn't help the distribution, but help with the abnormalty.\n",
    "\n",
    "**Conclusion** - yeo_johnson have been selected for this transformation.\n",
    "\n",
    "\n",
    "23. **YearRemodAdd:** It was possible to apply all the numerical Transformer. No improvement seen in distribution from any of the transformed variable.\n",
    "\n",
    "**Conclusion** - No transformer selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformer (base e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected variables for LogTransformer\n",
    "vars_engineering_log = ['1stFlrSF', 'GrLivArea', 'LotArea']\n",
    "vars_engineering_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selected transformation to the Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_var = vt.LogTransformer(variables=vars_engineering_log)\n",
    "TrainSet = transformed_var.fit_transform(TrainSet)\n",
    "TestSet = transformed_var.transform(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected variables for PowerTransformer\n",
    "vars_engineering_power =  ['BsmtFinSF1', 'BsmtUnfSF', 'GarageArea']\n",
    "vars_engineering_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selected transformation to the Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_var = vt.PowerTransformer(variables=vars_engineering_power)\n",
    "TrainSet = transformed_var.fit_transform(TrainSet)\n",
    "TestSet = transformed_var.transform(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yeo Johnson Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected variables for Yeo-JohnsonTransformer\n",
    "vars_engineering_yj = ['GarageYrBlt', 'LotFrontage', 'OpenPorchSF', 'TotalBsmtSF', 'YearBuilt']\n",
    "vars_engineering_yj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selected transformation to the Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_var = vt.YeoJohnsonTransformer(variables=vars_engineering_yj)\n",
    "TrainSet = transformed_var.fit_transform(TrainSet)\n",
    "TestSet = transformed_var.transform(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply all numerical variables except the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering = (TrainSet.select_dtypes(include=['float', 'int']).columns.to_list())\n",
    "variables_engineering.remove('SalePrice')\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame, with the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the engineered variables and apply the transformations, assess the engineered variables distribution and select the most suitable method for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='outlier_winsorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable transformation distribution analysis - Assess variables distribution to select the most suitable method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables Selected: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected variables for Outlier Transformer\n",
    "vars_engineering_outlier = ['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage', 'TotalBsmtSF']\n",
    "vars_engineering_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selected transformation to the Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_var = Winsorizer(\n",
    "        capping_method='iqr', tail='both', fold=1.5, variables=vars_engineering_outlier)\n",
    "\n",
    "TrainSet = transformed_var.fit_transform(TrainSet)\n",
    "TestSet = transformed_var.transform(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Correlated Selection Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds groups of correlated features and then selects, from each group for evaluation\n",
    "\n",
    "For this transformer, we apply all numerical variables except the target variable to the transformer - the aim is to leave the target variable untouched as it represents the outcome or dependent variable we are trying to predict or understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering = (TrainSet.select_dtypes(include=['float', 'int']).columns.to_list())\n",
    "variables_engineering.remove('SalePrice')\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the method as Pearson, the threshold as 0.7 and selection_method as the variance. A threshold of 0.7 means that any variable correlations that are above the threshold, will be considered and subject to removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.7, selection_method=\"variance\")\n",
    "\n",
    "# We can check which sets of features were marked as correlated \n",
    "corr_sel.fit_transform(df_engineering)\n",
    "corr_sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check which variables were removed\n",
    "corr_sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusions and Next steps:** \n",
    "\n",
    "The list below shows the transformations needed for feature engineering which will be added to the ML Pipeline.\n",
    "\n",
    "Feature Engineering Transformers\n",
    "\n",
    "* Ordinal Encoder: 'BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'\n",
    "\n",
    "* Numerical Transformers:\n",
    "  * Log Transformer (base e): '1stFlrSF', 'GrLivArea', 'LotArea'\n",
    "  * Power Transformer: 'BsmtFinSF1', 'BsmtUnfSF', 'GarageArea'\n",
    "  * Yeo Johnson Transformer: 'GarageYrBlt', 'LotFrontage', 'OpenPorchSF', 'TotalBsmtSF', 'YearBuilt'\n",
    "  \n",
    "* Outlier Transformer:\n",
    "   * Winzorizer: '1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage', 'TotalBsmtSF'\n",
    "\n",
    "* Smart Correlated Selection: '1stFlrSF', 'GarageYrBlt', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd'\n",
    "* Dropped Variables: '1stFlrSF', 'YearBuilt', 'YearRemodAdd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Clear the outputs, and move on to the following notebook."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
   "language": "python",
   "name": "python381264bit3812pyenv5b80354a30f64bb4ae7133543a9ca1d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
